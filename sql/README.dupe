Duplicates can be caught using various algorithms:
==> dedupe_alg1.sql <== barcode and sortname
==> dedupe_alg2.sql <== ZIP and sortname
==> dedupe_alg3.sql <== barcode, first and last name
==> dedupe_alg4.sql <== sortname
==> dedupe_alg5.sql <== barcode and initials -- no organizations
==> dedupe_alg6.sql <== barcode and first name
==> dedupe_alg7.sql <== phone number
==> dedupe_alg8.sql <== email
==> dedupe_alg9.sql <== barcode

Best practice is to start by standardizing addresses and
producing barcodes for each address. Then update the contact
table with these results. Make sure data is clean, fields are
TRIMmed and NULLed where appropriate. Look at dedupe_prep.sql for
help on this stage.

Then, repeat the following as necessary, varying the algorithm
file, until the reports uniformly show "few enough" actual
duplicates, at which point your job is done.

- Run dedupe_algX.sql to populate the dupe_key field.
- Run dedupe.sql to create the dupe_sets table.
- Manually review the dataset using a dedupe report. Look for
  your best guess at the ratio between actual duplicates and
  false matches. 
  - If there are mostly false matches, you may want to abort and
    try the next algorithm. 
  - Alternatively, especially if the overall numbers are small,
    you might want to run a DELETE query like:
    # DELETE FROM dupe_sets 
      WHERE tossid NOT IN 
      (LIST_OF_TOSS_IDS_THAT_ARE_IN_REAL_DUPE_SETS);
    This removes false matches from dupe_sets. You can now re-run
    the report to verify that you're about to merge only real
    duplicate sets.
- Run dupeswapper.sql to move the most recent record into the keep
  position.
- If appropriate, swap individual sets back as necessary:
  # SELECT swap( <CURRENT_KEEP_ID>, <CURRENT_TOSS_ID> ); 
  but if you do this, also rerun this part of dupeswapper to
  clean up circularity problems:
  # DELETE FROM dupe_sets 
    WHERE tossid IN (SELECT keepid FROM dupe_sets);
- Re-run the dupe report for common sense check.

Repeat the above as often as necessary with different algorithm
queries. In general, start with the lower numbered queries and
work your way up to the higher numbers.
